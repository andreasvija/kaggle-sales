{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_importances(model, error=False):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.title(\"Feature importances\")\n",
    "    \n",
    "    if error:\n",
    "        std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "        plt.barh(range(train_X.shape[1]), importances[indices], yerr=std[indices], align=\"center\")\n",
    "    else:\n",
    "        plt.barh(range(train_X.shape[1]), importances[indices], align=\"center\")\n",
    "    \n",
    "    plt.xticks(range(train_X.shape[1]), [train_X.columns[ix] for ix in indices], rotation='vertical')\n",
    "    plt.xlim([-1, train_X.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.792 1st place  \n",
    "0.882 top 1%  \n",
    "0.898 top 5%  \n",
    "0.906 top 10%  \n",
    "0.911 top 20%  \n",
    "1.040 top 50%  \n",
    "1.239 top 75%  \n",
    "\n",
    "just guessing 0 on my test set - 1.975  \n",
    "time,shop,item,price,category,last 12 counts RF(n=50,min_leaf=5) - 1.465 (41 min, n=300,min_leaf=1 estimated 224 min)  \n",
    "same + last 12 general shop and item counts - 1.476 (145 min)  \n",
    "same but [1,2,3,6,12] - 1.600 (42 min)\n",
    "same + month, word embeddings[2,3,5] - 1.447 (74 min)  \n",
    "same but all 12 specific counts - 1.672 (88 min)  \n",
    "time,shop,item,price,category,last 12 counts, month, word embeddings - 1.447 (69 min)  \n",
    "everything so far - 1.499 (124 min), 1.467 (112 min)  \n",
    "everything min_leaf=1 - 1.563 (147 min)  \n",
    "\n",
    "everything extra trees(n=50,min_leaf=5) - 1.400 (68 min)  \n",
    "everything gradient boosting(50, min_leaf=1) - 1.360 (11 min), 1.375 (11 min), min_leaf=5 1.362 (11 min)  \n",
    "everything gradient boosting 200 - 1.432 (52 min)  \n",
    "gradient 50 word embeddings[1,1,2] - 1.354 (16 min), 1.357 (15 min)  \n",
    "same + year, month_length, last_revenue, last 12 category counts - 1.458 (22 min)  \n",
    "same + [3,6,12] means of all counts - 1.379 (20 min)  \n",
    "same but months[1,2,3,6,12] - 1.952 (15 min)  \n",
    "same but meanless - 1.602 (8 min)  \n",
    "same but all store item counts - 1.988 (9 min)  \n",
    "same minus useless single features - 1.571 (8 min) 1.568  \n",
    "\n",
    "same but count clipped to (0,20) - 0.849 (8 min)  \n",
    "same minus price and last revenue  - 0.849 (8 min)  \n",
    "same + last premean revenue, total item return% - 0.849  \n",
    "undo clip(0,20) for one run - 1.319  \n",
    "month fix, added predict week, shop, item - 0.842; kaggle - 1.02109  \n",
    "same but RF - 0.895 (57 min); kaggle - 1.11769  \n",
    "g50 unregularized mean encodings - 0.882; kaggle - 1.05080  \n",
    "+mõni 0.884  \n",
    "\n",
    "every feature with gradient(50) -                                  0.840 (0.670) (24 min) kaggle 1.09106  \n",
    "every feature with gradient(early=30, 0.6col, 0.8row)(500 trees) - 0.847 (0.570) (252 min) kaggle 1.11813  \n",
    "every feature with RF(50) -                                        0.905 (0.187) (87 min) kaggle 1.13444  \n",
    "every feature with RF(300, 0.6col) -                               0.887 (0.180) (140 min) kaggle 1.10903  \n",
    "every feature with extra trees(300, 0.6col) -                      0.873 (0.185) (79 min) kaggle 1.07838  \n",
    "gradient(50) + tSNE -                                              0.840 (0.671) (29 min)  \n",
    "\n",
    "minus cheaps with gradient(early=30, 0.6col, 0.8row)(xx trees) -   0.752 (0.676) (259 min) kaggle 1.02715  \n",
    "minus cheaps with RF(300, 0.6col) -                                0.744 (0.210) (173 min) kaggle 1.03641  \n",
    "\n",
    "even harsher with gradient(early=30, 0.6col, 0.8row)(xx trees) -   0.xxx (0.xxx) ( min) kaggle x.xxxxx  \n",
    "even harsher with RF(300, 0.6col) -                                0.xxx (0.xxx) ( min) kaggle x.xxxxx  \n",
    "even harsher with extra trees(300, 0.6col) -                       0.xxx (0.xxx) ( min) kaggle x.xxxxx   \n",
    "even harsher with xgboost(early=30, 0.6col, 0.8row)(xx trees) -    0.xxx (0.xxx) ( min) kaggle x.xxxxx  \n",
    "\n",
    "uued definitsioonid - cheaps(possible overreliance nii all kui ka minus cheaps sees, enamasti mingi count, esimesed 1-5, loogiliselt natuke laiendada), strongs(väga kasulikud aga mitte juhid), thirds(üle mingi thresholdi mingis joonises); definitely shit(madalad peaaegu igal pool)  \n",
    "minus cheaps with big deep (kernel?) xgboost (xx trees) -          0.xxx (0.xxx) ( min) kaggle x.xxxxx  \n",
    "\n",
    "feature selection tööriistad  \n",
    "kernel  \n",
    "proovida juhuslikke subsete parimate hulgast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = ''\n",
    "\n",
    "show_error_bars = False\n",
    "model_class = GradientBoostingRegressor\n",
    "model_params = {\n",
    "    'n_estimators': 50,\n",
    "    #'n_jobs': -1 # RF\n",
    "    'max_depth': 8, # GBT\n",
    "    'subsample': 0.8, # GBT\n",
    "    'max_features': 0.8,\n",
    "    'learning_rate': 0.3,\n",
    "    'min_samples_split': 300\n",
    "}\n",
    "\n",
    "# remember to set LAST_TRAINSET_TIME in notebooks A and B to \n",
    "# 29 for develop, 33 for submit for correct/best results, \n",
    "# otherwise mean encodings and return% will overfit\n",
    "submit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4555656 entries, 0 to 4555655\n",
      "Columns: 33 entries, item_count_lag_1 to time\n",
      "dtypes: float16(11), float32(9), int16(7), int8(6)\n",
      "memory usage: 338.9 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_count_lag_1</th>\n",
       "      <th>all_data_PCA_vector_4</th>\n",
       "      <th>item_price_lag_3</th>\n",
       "      <th>item_price_lag_1</th>\n",
       "      <th>shop</th>\n",
       "      <th>revenue_3_mean</th>\n",
       "      <th>shop_count_per_item_12_mean</th>\n",
       "      <th>item_name_vector_3</th>\n",
       "      <th>item_return_percent</th>\n",
       "      <th>shop_city</th>\n",
       "      <th>shop_count_per_item_lag_1</th>\n",
       "      <th>count_lag_2</th>\n",
       "      <th>item_count_lag_6</th>\n",
       "      <th>item_name_vector_2</th>\n",
       "      <th>shop_category_mean_count</th>\n",
       "      <th>months_since_last_item_sale</th>\n",
       "      <th>count</th>\n",
       "      <th>category_mean_count</th>\n",
       "      <th>item_price_lag_2</th>\n",
       "      <th>count_lag_3</th>\n",
       "      <th>all_data_PCA_vector_1</th>\n",
       "      <th>revenue_12_mean</th>\n",
       "      <th>shop_category_count_per_item_6_mean</th>\n",
       "      <th>item_name_vector_1</th>\n",
       "      <th>all_data_PCA_vector_3</th>\n",
       "      <th>item_count_lag_12</th>\n",
       "      <th>item_price_lag_6</th>\n",
       "      <th>shop_type</th>\n",
       "      <th>shop_item_mean_count</th>\n",
       "      <th>category_count_per_item_6_mean</th>\n",
       "      <th>item</th>\n",
       "      <th>larger_category</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>795.806580</td>\n",
       "      <td>209.084213</td>\n",
       "      <td>168.530563</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.179077</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>14</td>\n",
       "      <td>0.134644</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.162231</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>168.811111</td>\n",
       "      <td>0</td>\n",
       "      <td>-726.214905</td>\n",
       "      <td>63.166668</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>0.096497</td>\n",
       "      <td>-29.806570</td>\n",
       "      <td>0</td>\n",
       "      <td>398.994446</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095215</td>\n",
       "      <td>5.074219</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>145.899826</td>\n",
       "      <td>570.881226</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.062225</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>14</td>\n",
       "      <td>0.134644</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.141602</td>\n",
       "      <td>0.043701</td>\n",
       "      <td>-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>496.227783</td>\n",
       "      <td>0</td>\n",
       "      <td>78.319992</td>\n",
       "      <td>349.458344</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>0.903809</td>\n",
       "      <td>-1300.056030</td>\n",
       "      <td>0</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047607</td>\n",
       "      <td>3.447266</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>683.887878</td>\n",
       "      <td>207.253983</td>\n",
       "      <td>145.983337</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.705078</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>14</td>\n",
       "      <td>0.134644</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0.124023</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-909.651428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>1.804688</td>\n",
       "      <td>-97.263023</td>\n",
       "      <td>189</td>\n",
       "      <td>348.998230</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>5.074219</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>568.018188</td>\n",
       "      <td>194.372742</td>\n",
       "      <td>196.047623</td>\n",
       "      <td>2</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.227783</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>14</td>\n",
       "      <td>0.134644</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0.538086</td>\n",
       "      <td>0.043701</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136230</td>\n",
       "      <td>192.800003</td>\n",
       "      <td>0</td>\n",
       "      <td>-581.274414</td>\n",
       "      <td>91.333336</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>2.429688</td>\n",
       "      <td>-445.097900</td>\n",
       "      <td>45</td>\n",
       "      <td>194.372742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333252</td>\n",
       "      <td>3.447266</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>635.910706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>-0.443359</td>\n",
       "      <td>0.029419</td>\n",
       "      <td>14</td>\n",
       "      <td>0.134644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.479492</td>\n",
       "      <td>0.041321</td>\n",
       "      <td>-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1015.439575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022018</td>\n",
       "      <td>0.336670</td>\n",
       "      <td>-40.430794</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.207031</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_count_lag_1  all_data_PCA_vector_4  item_price_lag_3  \\\n",
       "0                40             795.806580        209.084213   \n",
       "1                18             145.899826        570.881226   \n",
       "2                77             683.887878        207.253983   \n",
       "3                38             568.018188        194.372742   \n",
       "4                 0             635.910706          0.000000   \n",
       "\n",
       "   item_price_lag_1  shop  revenue_3_mean  shop_count_per_item_12_mean  \\\n",
       "0        168.530563     2             0.0                     0.057373   \n",
       "1        499.000000     2             0.0                     0.057373   \n",
       "2        145.983337     2             0.0                     0.057373   \n",
       "3        196.047623     2           199.0                     0.057373   \n",
       "4          0.000000     2             0.0                     0.057373   \n",
       "\n",
       "   item_name_vector_3  item_return_percent  shop_city  \\\n",
       "0            0.179077             0.000479         14   \n",
       "1            0.062225             0.003515         14   \n",
       "2            0.705078             0.000965         14   \n",
       "3            0.227783             0.004856         14   \n",
       "4           -0.443359             0.029419         14   \n",
       "\n",
       "   shop_count_per_item_lag_1  count_lag_2  item_count_lag_6  \\\n",
       "0                   0.134644            0                30   \n",
       "1                   0.134644            0                13   \n",
       "2                   0.134644            0                79   \n",
       "3                   0.134644            2                38   \n",
       "4                   0.134644            0                 0   \n",
       "\n",
       "   item_name_vector_2  shop_category_mean_count  months_since_last_item_sale  \\\n",
       "0           -0.162231                  0.046448                          -23   \n",
       "1            0.141602                  0.043701                          -23   \n",
       "2            0.124023                  0.046448                          -23   \n",
       "3            0.538086                  0.043701                          -23   \n",
       "4           -0.479492                  0.041321                          -23   \n",
       "\n",
       "   count  category_mean_count  item_price_lag_2  count_lag_3  \\\n",
       "0      0             0.169922        168.811111            0   \n",
       "1      0             0.136230        496.227783            0   \n",
       "2      1             0.169922        149.000000            0   \n",
       "3      1             0.136230        192.800003            0   \n",
       "4      0             0.151611          0.000000            0   \n",
       "\n",
       "   all_data_PCA_vector_1  revenue_12_mean  \\\n",
       "0            -726.214905        63.166668   \n",
       "1              78.319992       349.458344   \n",
       "2            -909.651428         0.000000   \n",
       "3            -581.274414        91.333336   \n",
       "4           -1015.439575         0.000000   \n",
       "\n",
       "   shop_category_count_per_item_6_mean  item_name_vector_1  \\\n",
       "0                             0.022171            0.096497   \n",
       "1                             0.016769            0.903809   \n",
       "2                             0.022171            1.804688   \n",
       "3                             0.016769            2.429688   \n",
       "4                             0.022018            0.336670   \n",
       "\n",
       "   all_data_PCA_vector_3  item_count_lag_12  item_price_lag_6  shop_type  \\\n",
       "0             -29.806570                  0        398.994446          0   \n",
       "1           -1300.056030                  0        699.000000          0   \n",
       "2             -97.263023                189        348.998230          0   \n",
       "3            -445.097900                 45        194.372742          0   \n",
       "4             -40.430794                  0          0.000000          0   \n",
       "\n",
       "   shop_item_mean_count  category_count_per_item_6_mean  item  \\\n",
       "0              0.095215                        5.074219    30   \n",
       "1              0.047607                        3.447266    31   \n",
       "2              0.523926                        5.074219    32   \n",
       "3              0.333252                        3.447266    33   \n",
       "4              0.000000                        4.207031    38   \n",
       "\n",
       "   larger_category  time  \n",
       "0               10    12  \n",
       "1               10    12  \n",
       "2               10    12  \n",
       "3               10    12  \n",
       "4               10    12  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   # - decidedly useless\n",
    "# - cheap/powerful\n",
    "model_features = [\n",
    "    'count', # label, dropped later\n",
    "    'item', # need for prediction S,S,3,\n",
    "    'shop', # need for prediction S,S,S,\n",
    "    'time', # need for prediction 3,S,3,3\n",
    "    \n",
    "    'shop_city', # S,S,S,3x trash candidate, all trash\n",
    "    'shop_type', # S,S,S,3x trash candidate, all trash\n",
    "    'category', # S,S,S,3k trash candidate\n",
    "    'larger_category', # S,S,S,3x trash candidate, all trash\n",
    "    'item_return_percent', # S,3,-,\n",
    "    \n",
    "    'month', # 3,-,-,3 cheap candidate, old cheap\n",
    "    #'year', # S,S,S,\n",
    "    #'month_length', # S,S,S,\n",
    "    #'holidays_in_month', # S,S,S,\n",
    "    \n",
    "    #'shop_mean_count', # S,S,33,3\n",
    "    'category_mean_count', # S,3,S,\n",
    "    'item_mean_count', # 3,-,-,2 cheap candidate, old cheap, chosen cheap, best cheap subset\n",
    "    'shop_item_mean_count', # 1,-,-, cheap candidate, old cheap, chosen cheap, best cheap subset\n",
    "    'shop_category_mean_count', # S,2,-,2 cheap candidate, best cheap subset\n",
    "    \n",
    "    'count_trend', # 3,3,-,3\n",
    "    'item_count_trend', # 2,2,-, cheap candidate\n",
    "    'item_price_trend', # S,S,S,2k trash candidate\n",
    "    'months_since_first_item_sale', # 2,3,-, cheap candidate\n",
    "    'months_since_last_item_sale', # S3,S3,-,3\n",
    "    'months_since_first_sale', # 2,2,-, cheap candidate\n",
    "    'months_since_last_sale', # 3,3,-,3\n",
    "    \n",
    "    'item_name_vector_1', # S,S,S32, trash candidate, all trash\n",
    "    'item_name_vector_2', # S,S,S3, trash candidate, all trash\n",
    "    'item_name_vector_3', # S,3,33, trash candidate, all trash\n",
    "    #'item_name_tSNE_vector_1', # S,S,S32,\n",
    "    #'item_name_tSNE_vector_2', # S,S,S32,\n",
    "    'all_data_PCA_vector_1', # S,S,1131, trash candidate\n",
    "    'all_data_PCA_vector_2', # S,S,223, trash candidate\n",
    "    'all_data_PCA_vector_3', # S,3,223, trash candidate, all trash\n",
    "    'all_data_PCA_vector_4', # S,S,322, trash candidate, all trash\n",
    "    \n",
    "    #'shop_price_lag_1', # S,S,S,\n",
    "    #'category_price_lag_1', # S,S,S,\n",
    "    #'shop_revenue_lag_1', # S,S,\n",
    "    #'category_revenue_lag_1', # S,S,S,\n",
    "    'item_revenue_lag_1', # S,S,2 trash candidate\n",
    "    \n",
    "    'count_lag_1', # 1,-,-,1 cheap candidate, old cheap, best cheap subset\n",
    "    'count_lag_2', # S,-,-,2 cheap candidate, old cheap, chosen cheap\n",
    "    'count_lag_3', # S,-,-,2 cheap candidate, old cheap, chosen cheap, best cheap subset\n",
    "    #'count_lag_4', # S,S,2211,\n",
    "    #'count_lag_5', # S,S,3,3x\n",
    "    #'count_lag_6', # S,S,3,2\n",
    "    #'count_lag_7', # S,S,SS33,3\n",
    "    #'count_lag_8', # S,S,32,2\n",
    "    #'count_lag_9', # S,S,S,33\n",
    "    #'count_lag_10', # S,S,S,\n",
    "    #'count_lag_11', # S,S,S,\n",
    "    #'count_lag_12', # S,S,S,3\n",
    "    'count_12_mean', # 3,1,-, cheap candidate, best cheap subset\n",
    "    'count_6_mean', # 2,-,-, cheap candidate, old cheap\n",
    "    'count_3_mean', # 1,-,-, cheap candidate, old cheap\n",
    "    \n",
    "    'item_count_lag_1', # 3,-,-,21 cheap candidate, old cheap\n",
    "    #'item_count_lag_2', # S,S,2213,\n",
    "    #'item_count_lag_3', # S,S,3,3\n",
    "    #'item_count_lag_4', # \n",
    "    #'item_count_lag_5', # \n",
    "    'item_count_lag_6', # S,S,SS3, trash candidate\n",
    "    #'item_count_lag_7', # \n",
    "    #'item_count_lag_8', # \n",
    "    #'item_count_lag_9', # \n",
    "    #'item_count_lag_10', # \n",
    "    #'item_count_lag_11', # \n",
    "    'item_count_lag_12', # S,S,S,3 trash candidate, all trash\n",
    "    'item_count_12_mean', # 3,3,S, cheap candidate\n",
    "    'item_count_6_mean', # 3,S,2212 cheap candidate, best cheap subset\n",
    "    'item_count_3_mean', # S,2,-,\n",
    "    \n",
    "    #'shop_count_lag_1', # S,S,S,\n",
    "    #'shop_count_lag_2', # S,S,S,\n",
    "    #'shop_count_lag_3', # S,S,S,\n",
    "    #'shop_count_lag_4', # \n",
    "    #'shop_count_lag_5', # \n",
    "    #'shop_count_lag_6', # S,S,S,\n",
    "    #'shop_count_lag_7', # \n",
    "    #'shop_count_lag_8', # \n",
    "    #'shop_count_lag_9', # \n",
    "    #'shop_count_lag_10', # \n",
    "    #'shop_count_lag_11', # \n",
    "    'shop_count_lag_12', # S,S,S,32x\n",
    "    #'shop_count_12_mean', # S,S,S,\n",
    "    #'shop_count_6_mean', # S,S,S,\n",
    "    #'shop_count_3_mean', # S,S,S,\n",
    "    \n",
    "    'shop_count_per_item_lag_1', # S,S,SSS2, trash candidate\n",
    "    #'shop_count_per_item_lag_2', # S,S,S,\n",
    "    #'shop_count_per_item_lag_3', # S,S,S,\n",
    "    #'shop_count_per_item_lag_4', # \n",
    "    #'shop_count_per_item_lag_5', # \n",
    "    #'shop_count_per_item_lag_6', # S,S,S,\n",
    "    #'shop_count_per_item_lag_7', # \n",
    "    #'shop_count_per_item_lag_8', # \n",
    "    #'shop_count_per_item_lag_9', # \n",
    "    #'shop_count_per_item_lag_10', # \n",
    "    #'shop_count_per_item_lag_11', # \n",
    "    'shop_count_per_item_lag_12', # S,S,33,3\n",
    "    'shop_count_per_item_12_mean', # S,S,SSS3,3X\n",
    "    #'shop_count_per_item_6_mean', # S,S,S,\n",
    "    #'shop_count_per_item_3_mean', # S,S,S,\n",
    "    \n",
    "    'category_count_per_item_lag_1', # S,S,3,\n",
    "    #'category_count_per_item_lag_2', # S,S,SSS2,\n",
    "    #'category_count_per_item_lag_3', # S,S,S,\n",
    "    #'category_count_per_item_lag_4', # \n",
    "    #'category_count_per_item_lag_5', # \n",
    "    #'category_count_per_item_lag_6', # S,S,S,\n",
    "    #'category_count_per_item_lag_7', # \n",
    "    #'category_count_per_item_lag_8', # \n",
    "    #'category_count_per_item_lag_9', # \n",
    "    #'category_count_per_item_lag_10', # \n",
    "    #'category_count_per_item_lag_11', # \n",
    "    #'category_count_per_item_lag_12', # S,S,S,\n",
    "    'category_count_per_item_12_mean', # S,S,S,2x\n",
    "    'category_count_per_item_6_mean', # S,S,SSS2, trash candidate, all trash\n",
    "    'category_count_per_item_3_mean', # S,S,SSS2,\n",
    "    \n",
    "    'shop_category_count_per_item_lag_1', # S,32,-,2 cheap candidate, best cheap subset\n",
    "    #'shop_category_count_per_item_lag_2', # S,S,2\n",
    "    #'shop_category_count_per_item_lag_3', # S,S,S33,\n",
    "    #'shop_category_count_per_item_lag_4', # \n",
    "    #'shop_category_count_per_item_lag_5', # \n",
    "    #'shop_category_count_per_item_lag_6', # S,S,S,\n",
    "    #'shop_category_count_per_item_lag_7', # \n",
    "    #'shop_category_count_per_item_lag_8', # \n",
    "    #'shop_category_count_per_item_lag_9', # \n",
    "    #'shop_category_count_per_item_lag_10', # \n",
    "    #'shop_category_count_per_item_lag_11', # \n",
    "    #'shop_category_count_per_item_lag_12', # S,S,S,\n",
    "    'shop_category_count_per_item_12_mean', # S,S,233,\n",
    "    'shop_category_count_per_item_6_mean', # S,S,2,3 trash candidate, all trash\n",
    "    'shop_category_count_per_item_3_mean', # S,3,-,2x cheap candidate, best cheap subset\n",
    "    \n",
    "    'item_price_lag_1', # S,S,S,3 trash candidate, all trash\n",
    "    'item_price_lag_2', # S3,S,-,2 trash candidate, all trash\n",
    "    'item_price_lag_3', # S,S,2,2 trash candidate, all trash\n",
    "    #'item_price_lag_4', # \n",
    "    #'item_price_lag_5', # \n",
    "    'item_price_lag_6', # S,S,S,3x trash candidate, all trash\n",
    "    #'item_price_lag_7', # \n",
    "    #'item_price_lag_8', # \n",
    "    #'item_price_lag_9', # \n",
    "    #'item_price_lag_10', # \n",
    "    #'item_price_lag_11', # \n",
    "    #'item_price_lag_12', # S,S,S,\n",
    "    'item_price_12_mean', # 2,2,-, cheap candidate, best cheap subset\n",
    "    'item_price_6_mean', # S3,3,-,3 cheap candidate\n",
    "    'item_price_3_mean', # S,S,2,2 \n",
    "    \n",
    "    'revenue_lag_1', # S,1,-,3 cheap candidate, chosen cheap, best cheap subset\n",
    "    #'revenue_lag_2', # S,S,23\n",
    "    #'revenue_lag_3', # S,S,S,\n",
    "    #'revenue_lag_4', # \n",
    "    #'revenue_lag_5', # \n",
    "    #'revenue_lag_6', # S,S,S,\n",
    "    #'revenue_lag_7', # \n",
    "    #'revenue_lag_8', # \n",
    "    #'revenue_lag_9', # \n",
    "    #'revenue_lag_10', # \n",
    "    #'revenue_lag_11', # \n",
    "    #'revenue_lag_12', # S,S,S,\n",
    "    'revenue_12_mean', # S,3,-, thrash candidate, all trash\n",
    "    #'revenue_6_mean', # S,3,-,\n",
    "    'revenue_3_mean' # S,2,-,1 cheap candidate\n",
    "]\n",
    "\n",
    "data = pd.read_pickle('data/features_submit.p')[model_features]\n",
    "print(data.info(max_cols=1))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Development model training\n",
    "\n",
    "if not submit:\n",
    "\n",
    "    # Data split\n",
    "\n",
    "    train = data[data['time'] < 30]\n",
    "    #train = train.sample(frac=0.1)\n",
    "    validate = data[(data['time'] >= 30) & (data['time'] < 34)]\n",
    "    #(predict = data[data['time'] == 34])\n",
    "\n",
    "    train_X = train.drop('count', axis=1)\n",
    "    train_y = train['count']\n",
    "    del train\n",
    "    validate_X = validate.drop('count', axis=1)\n",
    "    validate_y = validate['count']\n",
    "    del validate\n",
    "\n",
    "    # Train\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    model = model_class(**model_params)\n",
    "    model.fit(train_X, train_y)\n",
    "\n",
    "    print('({} min)'.format(round((time()-start)/60, 1)))\n",
    "\n",
    "    # Validate\n",
    "\n",
    "    print('train RMSE: {}'.format(np.sqrt(MSE(model.predict(train_X), train_y))))\n",
    "    print('validation RMSE: {}'.format(np.sqrt(MSE(model.predict(validate_X), validate_y))))\n",
    "    \n",
    "    # Analysis\n",
    "    \n",
    "    plot_importances(model, error=show_error_bars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Submission model training\n",
    "\n",
    "if submit:\n",
    "\n",
    "    # Data split\n",
    "\n",
    "    train = data[data['time'] < 33]\n",
    "    validate = data[data['time'] == 33]\n",
    "    predict = data[data['time'] == 34]\n",
    "\n",
    "    train_X = train.drop('count', axis=1)\n",
    "    train_y = train['count']\n",
    "    del train\n",
    "    validate_X = validate.drop('count', axis=1)\n",
    "    validate_y = validate['count']\n",
    "    del validate\n",
    "    predict_X = predict.drop('count', axis=1)\n",
    "\n",
    "    # Train\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    model = model_class(**model_params)\n",
    "    model.fit(train_X, train_y)\n",
    "\n",
    "    print('({} min)'.format(round((time()-start)/60, 1)))\n",
    "\n",
    "    # Validate\n",
    "\n",
    "    print('train RMSE: {}'.format(np.sqrt(MSE(model.predict(train_X), train_y))))\n",
    "    print('validation RMSE: {}'.format(np.sqrt(MSE(model.predict(validate_X), validate_y))))\n",
    "    \n",
    "    # Analysis\n",
    "    \n",
    "    plot_importances(model, error=show_error_bars)\n",
    "\n",
    "    # Prediction\n",
    "\n",
    "    final_prediction = model.predict(predict_X)\n",
    "    print(np.max(final_prediction), 'should be <= 20')\n",
    "    print(np.min(final_prediction), 'should be >= 0')\n",
    "    final_prediction = np.clip(final_prediction, 0, 20)\n",
    "\n",
    "    prediction = predict_X[['shop', 'item']]\n",
    "    prediction.columns = ['shop_id', 'item_id']\n",
    "    prediction['item_cnt_month'] = final_prediction\n",
    "    prediction = pd.merge(prediction, pd.read_csv('data/test.csv'), how='right')\n",
    "    prediction['item_cnt_month'].fillna(0, inplace=True) # maybe something better can be done?\n",
    "\n",
    "    prediction.sort_values(by='ID', inplace=True)\n",
    "    prediction = prediction[['ID', 'item_cnt_month']]\n",
    "    print(len(prediction), 'should be 214200')\n",
    "\n",
    "    print()\n",
    "    print('Features:', ', '.join(model_features))\n",
    "    print('Model:', type(model))\n",
    "    print('Parameters:', str(model_params))\n",
    "    print('Description:', description)\n",
    "\n",
    "    prediction.to_csv('data/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
