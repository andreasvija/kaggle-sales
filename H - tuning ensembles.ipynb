{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_TRAINSET_TIME = 33\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "totalstart=time()\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 792288 entries, 0 to 792287\n",
      "Data columns (total 10 columns):\n",
      "item                792288 non-null int16\n",
      "shop                792288 non-null int8\n",
      "time                792288 non-null int8\n",
      "XGB all             792288 non-null float32\n",
      "XGB minus cheaps    792288 non-null float32\n",
      "GBR all             792288 non-null float64\n",
      "GBR minus cheaps    792288 non-null float64\n",
      "RF all              792288 non-null float64\n",
      "RF minus cheaps     792288 non-null float64\n",
      "count               792288 non-null int16\n",
      "dtypes: float32(2), float64(4), int16(2), int8(2)\n",
      "memory usage: 40.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle('data/ensemble_develop.p')#.sample(frac=0.001)\n",
    "print(data.info())\n",
    "submit_data = pd.read_pickle('data/ensemble_submit.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = XGBRegressor\n",
    "params = {\n",
    "    'n_jobs': [-1],\n",
    "    'objective': ['reg:squarederror'],\n",
    "    'seed': [123],\n",
    "    \n",
    "    'learning_rate': [0.05],\n",
    "    'n_estimators': [330, 60],\n",
    "    #'early_stopping_rounds': [50],\n",
    "\n",
    "    'subsample': [0.6],\n",
    "    'colsample_bytree': [0.9],\n",
    "    \n",
    "    'max_depth': [1],\n",
    "    'min_child_weight': [100],\n",
    "    'reg_alpha': [0.5],\n",
    "    'reg_lambda': [0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "data/submission_330.csv <class 'xgboost.sklearn.XGBRegressor'> 330\n",
      "2\n",
      "data/submission_60.csv <class 'xgboost.sklearn.XGBRegressor'> 60\n"
     ]
    }
   ],
   "source": [
    "train = data[data['time'] <= LAST_TRAINSET_TIME]\n",
    "validate = data[(data['time'] > LAST_TRAINSET_TIME) & (data['time'] < 34)]\n",
    "\n",
    "train_X = train.drop('count', axis=1)\n",
    "train_y = train['count']\n",
    "del train\n",
    "validate_X = validate.drop('count', axis=1)\n",
    "validate_y = validate['count']\n",
    "del validate\n",
    "predict_X = submit_data.drop('count', axis=1)\n",
    "del data\n",
    "del submit_data\n",
    "\n",
    "results = {}\n",
    "for key in params.keys():\n",
    "    results[key] = []\n",
    "results['train'] = []\n",
    "#results['validate'] = []\n",
    "results['trees'] = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for combo in ParameterGrid(params):\n",
    "    n += 1\n",
    "    print(n)\n",
    "    \n",
    "    model_params = {\n",
    "        'n_jobs': combo['n_jobs'],\n",
    "        'objective': combo['objective'],\n",
    "        'seed': combo['seed'],\n",
    "        \n",
    "        'n_estimators': combo['n_estimators'],\n",
    "        \n",
    "        'subsample': combo['subsample'],\n",
    "        'colsample_bytree': combo['colsample_bytree'],\n",
    "\n",
    "        'learning_rate': combo['learning_rate'],\n",
    "        'max_depth': combo['max_depth'],\n",
    "        'min_child_weight': combo['min_child_weight'],\n",
    "        \n",
    "        'reg_alpha': combo['reg_alpha'],\n",
    "        'reg_lambda': combo['reg_lambda']\n",
    "    }\n",
    "\n",
    "    model = model_class(**model_params)\n",
    "\n",
    "    if model_class == XGBRegressor:\n",
    "        fit_params = {\n",
    "            #'early_stopping_rounds': combo['early_stopping_rounds']\n",
    "        }\n",
    "        \n",
    "        eval_set = [(train_X, train_y), (validate_X, validate_y)]\n",
    "        #model.fit(train_X, train_y, eval_set=eval_set, verbose=True, **fit_params)\n",
    "        model.fit(train_X, train_y, verbose=True, **fit_params)\n",
    "    else:\n",
    "        model.fit(train_X, train_y)\n",
    "\n",
    "    if model_class == XGBRegressor:\n",
    "        if 'early_stopping_rounds' in fit_params.keys() or 'n_estimators' not in model_params.keys():\n",
    "            ntree_limit = model.best_ntree_limit\n",
    "        else:\n",
    "            ntree_limit = model_params['n_estimators']\n",
    "        results['trees'].append(ntree_limit)\n",
    "\n",
    "    if model_class == XGBRegressor:\n",
    "        train_prediction = model.predict(train_X, ntree_limit=ntree_limit)\n",
    "        #validate_prediction = model.predict(validate_X, ntree_limit=ntree_limit)\n",
    "        final_prediction = model.predict(predict_X, ntree_limit=ntree_limit)\n",
    "    else:\n",
    "        train_prediction = model.predict(train_X)\n",
    "        validate_prediction = model.predict(validate_X)\n",
    "        #final_prediction = model.predict(predict_X)\n",
    "\n",
    "    for key in params.keys():\n",
    "        results[key].append(combo[key])\n",
    "\n",
    "    results['train'].append(np.sqrt(MSE(train_prediction, train_y)))\n",
    "    #results['validate'].append(np.sqrt(MSE(validate_prediction, validate_y)))\n",
    "    \n",
    "    if LAST_TRAINSET_TIME == 33:\n",
    "        filename = 'data/submission_{}.csv'.format(model_params['n_estimators'])\n",
    "        print(filename, model_class, model_params['n_estimators'])\n",
    "\n",
    "        final_prediction = np.clip(final_prediction, 0, 20)\n",
    "\n",
    "        prediction = predict_X[['shop', 'item']]\n",
    "        prediction.columns = ['shop_id', 'item_id']\n",
    "        prediction['item_cnt_month'] = final_prediction\n",
    "        prediction = pd.merge(prediction, pd.read_csv('data/test.csv'), how='right')\n",
    "        prediction['item_cnt_month'].fillna(0, inplace=True) # maybe something better can be done?\n",
    "\n",
    "        prediction.sort_values(by='ID', inplace=True)\n",
    "        prediction = prediction[['ID', 'item_cnt_month']]\n",
    "\n",
    "        prediction.to_csv(filename, index=False)\n",
    "\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>objective</th>\n",
       "      <th>seed</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>train</th>\n",
       "      <th>trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>123</td>\n",
       "      <td>0.05</td>\n",
       "      <td>330</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.723163</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>123</td>\n",
       "      <td>0.05</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.761941</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_jobs         objective  seed  learning_rate  n_estimators  subsample  \\\n",
       "0      -1  reg:squarederror   123           0.05           330        0.6   \n",
       "1      -1  reg:squarederror   123           0.05            60        0.6   \n",
       "\n",
       "   colsample_bytree  max_depth  min_child_weight  reg_alpha  reg_lambda  \\\n",
       "0               0.9          1               100        0.5         0.5   \n",
       "1               0.9          1               100        0.5         0.5   \n",
       "\n",
       "      train  trees  \n",
       "0  0.723163    330  \n",
       "1  0.761941     60  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results = results.sort_values(by='validate')\n",
    "#results['overfit'] = results['validate'] - results['train']\n",
    "#results['overfit_ratio'] = results['validate'] / results['train']\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.8 min\n",
      "total time: 0.0 h\n"
     ]
    }
   ],
   "source": [
    "print('total time:', round((time()-totalstart)/60, 1), 'min')\n",
    "print('total time:', round((time()-totalstart)/60/60, 1), 'h')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
